{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbtxQ4m4z87T"
   },
   "source": [
    "## Spark and Batch to predict customer churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88NwEZvOz87V"
   },
   "source": [
    "You will use a data set, **Telco Customer Churn**, which contains a telecommunications company's anonymous customer data . Use the details of this data set to predict customer churn, something which is critical to business as it's easier to retain existing customers rather to acquire new ones.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "In this notebook, you will learn how to:\n",
    "\n",
    "-  Load a CSV file into an Apache Spark DataFrame.\n",
    "-  Explore data.\n",
    "-  Prepare data for training and evaluation.\n",
    "-  Create an Apache Spark machine learning pipeline.\n",
    "-  Train and evaluate a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCBYH7vhz87b"
   },
   "source": [
    "<a id=\"load\"></a>\n",
    "## 1. Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIgn1KOuz87c"
   },
   "outputs": [],
   "source": [
    "df_data = spark.read.load(\"customer_churn.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\",option('nanValue', ' '),option('nullValue', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-qFHnQ8z87f"
   },
   "source": [
    "Explore the loaded data by using the following Apache Spark DataFrame methods:\n",
    "-  print schema\n",
    "-  count all records\n",
    "-  show distribution of label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceMubbaFz87f",
    "outputId": "52d03f05-2a21-4747-b2bc-dad87a3c3179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: integer (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: double (nullable = true)\n",
      " |-- TotalCharges: double (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n",
      "Number of fields:  21\n"
     ]
    }
   ],
   "source": [
    "df_data.printSchema()\n",
    "\n",
    "print(\"Number of fields: %3g\" % len(df_data.schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1jtOrwYz87k"
   },
   "source": [
    "As you can see, the data contains 21 fields. \"Churn\" field is the one you would like to predict (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESJZtVLEz87l",
    "outputId": "4f57d791-6ac7-4f45-8605-a3fe39e30bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 7043\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIj6etxHz87p"
   },
   "source": [
    "The data set contains 7043 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lth9rGYz87q"
   },
   "source": [
    "Now you will check if all records have complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awbFCz3kz87q",
    "outputId": "ba62a62c-362b-4e50-f5fb-9a9f0096a2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with complete data: 7032\n"
     ]
    }
   ],
   "source": [
    "df_complete = df_data.dropna()\n",
    "\n",
    "print(\"Number of records with complete data: %3g\" % df_complete.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxZNN0CSz87u"
   },
   "source": [
    "You can see that there are some missing values. You can investigate that all missing values are present in `TotalCharges` feature. For training and evaluation you will use the data set with the missing values removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1apbHk5z87w"
   },
   "source": [
    "Inspect the class distribution in the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZWQ_xa1z87x",
    "outputId": "d1d67f1f-3e40-4908-bf3b-6143184d68c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Churn|count|\n",
      "+-----+-----+\n",
      "|   No| 5163|\n",
      "|  Yes| 1869|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_complete.groupBy('Churn').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFDykdbbz871"
   },
   "source": [
    "<a id=\"model\"></a>\n",
    "## 2. Create an Apache Spark machine learning model\n",
    "\n",
    "In this section you will learn how to:\n",
    "\n",
    "- [2.1 Prepare data](#prep)\n",
    "- [2.2 Create an Apache Spark machine learning pipeline](#pipe)\n",
    "- [2.3 Train a model](#train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTF4-2yPz872"
   },
   "source": [
    "### 2.1 Prepare data<a id=\"prep\"></a>\n",
    "\n",
    "In this subsection you will split your data into: \n",
    "- train data set\n",
    "- test data set\n",
    "- predict data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmlyBsu6z872",
    "outputId": "ddacd9b8-b890-4d42-8862-d62fe8875fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records for training: 5638\n",
      "Number of records for evaluation: 1261\n",
      "Number of records for prediction: 133\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data, predict_data) = df_complete.randomSplit([0.8, 0.18, 0.02], 24)\n",
    "\n",
    "print(\"Number of records for training: \" + str(train_data.count()))\n",
    "print(\"Number of records for evaluation: \" + str(test_data.count()))\n",
    "print(\"Number of records for prediction: \" + str(predict_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck73s2QNz878"
   },
   "source": [
    "As you can see your data has been successfully split into three data sets: \n",
    "\n",
    "-  The train data set, which is the largest group, is used for training.\n",
    "-  The test data set will be used for model evaluation and to test the assumptions of the model.\n",
    "-  The predict data set will be used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntCTiO-bz878"
   },
   "source": [
    "### 2.2 Create the pipeline<a id=\"pipe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d47-pLkZz878"
   },
   "source": [
    "In this section you will create an Apache Spark machine learning pipeline and then train the model.\n",
    "\n",
    "In the first step you need to import the Apache Spark machine learning packages that will be needed in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzmQdjiQz879"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString, RFormula\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12J0WYkkz88B"
   },
   "source": [
    "In the following step, convert all the predictors to features vectors and convert the label feature to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84y2AM5Sz88D"
   },
   "outputs": [],
   "source": [
    "lab = StringIndexer(inputCol = 'Churn', outputCol = 'label')\n",
    "features = RFormula(formula = \"~ gender + SeniorCitizen +  Partner + Dependents + tenure + PhoneService + MultipleLines + InternetService + OnlineSecurity + OnlineBackup + DeviceProtection + TechSupport + StreamingTV + StreamingMovies + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ibzsYyJz88G"
   },
   "source": [
    "Next, define estimators you want to use for classification. Logistic Regression is used in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "6T5pT7uDB5pr",
    "outputId": "6b4ffe80-0918-40cf-ad0e-d9497d701ca3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'~ gender + SeniorCitizen +  Partner + Dependents + tenure + PhoneService + MultipleLines + InternetService + OnlineSecurity + OnlineBackup + DeviceProtection + TechSupport + StreamingTV + StreamingMovies + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges + TotalCharges'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.getFormula()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXGAB5rwz88H"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNxlW78pz88L"
   },
   "source": [
    "Now build the pipeline. A pipeline consists of transformers and an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4Ck2helz88L"
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages = [features, lab , lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KogHB9Voz88O"
   },
   "source": [
    "### 2.3 Train the model<a id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVRsXdE6z88P"
   },
   "source": [
    "Now, you can train your Logistic Regression model by using the previously defined **pipeline** and **train data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZS8OWk05z88Q"
   },
   "outputs": [],
   "source": [
    "model_lr = pipeline_lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heMpP9Zjz88V"
   },
   "source": [
    "You can check your **model accuracy** now. Use **test data** to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7YfvUPOz88W",
    "outputId": "d25ff672-e5a9-438f-9abe-2a8bb8bb46f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset:\n",
      "Accuracy = 0.80\n"
     ]
    }
   ],
   "source": [
    "predictions = model_lr.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test dataset:\")\n",
    "print(\"Accuracy = %3.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp6K04n2z88a"
   },
   "source": [
    "You can tune your model now to achieve better accuracy. For simplicity, the tuning example is omitted in this example."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09-predict-customer-churn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
